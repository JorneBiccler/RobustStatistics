d01 = simData$d01,
X = as.matrix(simData$X1),
init = c(-5, 0, 0 ,0),
breaks = c(0, 75, Inf),
lambda = 0.10)
penalizedMLE(timeVar = simData$timeVar,
d01 = simData$d01,
X = as.matrix(simData[c("X1", "X2", "X3", "X4")]),
init = c(log(sum(d01) / sum(timeVar)), 0, 5, 0, 0, 0, 0, 0, 0 ,0),
breaks = c(0, 75, Inf),
lambda = 0)
solutions <- NULL
for(lambda in c(0, 10^(seq(-10,0, 0.5)))){
solutions <- cbind(solutions,
penalizedMLE(timeVar = timeVar, d01 = d01, X = cbind(X1, X2, X3, X4),
init = c(-5, -1, 0, 0, 0, rep(0, 30)), breaks = c(0, 10, 20, 30, 40, 50, 60, Inf),
lambda = lambda)
)
}
penalizedBrier(timeVar = timeVar, d01 = d01, X = cbind(X1, X2, X3, X4), evalTimes = evalTimes,
cProbEvalTimes =  censoringProb, cProbTimeVar = censoringProb2,
breaks = c(0, 75, Inf),
init = c(-5, -1, 0, 0),
lambda = 0.000)
## test with PCH data
X <- mvrnorm(n = cleanN, mu = rep(0, nCov), diag(nCov))
time <- simulatePCH(cleanN, X, c(-5, -2, 0,0,0, -3, 1, 0,0,0), breaks = c(0, 150, Inf))
censoring <- rexp(cleanN, rate = 1 / exp(6))
timeVar <- pmin(time, censoring)
d01 <- as.numeric(time < censoring)
simData <- data.frame(timeVar, d01, X)
breaks <- c(seq(0, 200, 25), Inf)
## penalized MLE
maxLam <- lambdaMaxMLE(timeVar = simData$timeVar, d01 = simData$d01,
breaks = breaks,
X = as.matrix(simData[, !names(simData) %in% c("timeVar", "d01")]))
mlePath <- penalizedPathMLE(timeVar = simData$timeVar, d01 = simData$d01,
breaks = breaks,
X = as.matrix(simData[, !names(simData) %in% c("timeVar", "d01")]),
lambdaSeq = 10^seq(maxLam^(1/10),-10, by = -0.2))
cvSolution <- cvMLE(timeVar = simData$timeVar, d01 = simData$d01,
breaks = breaks,
X = as.matrix(simData[, !names(simData) %in% c("timeVar", "d01")]))
makePlot <- function(parameters, nCov, breaks){
for(i in 1:(nCov + 1)){
originalParam <-  as.numeric(paramTransMat(nIntervals = length(breaks) - 1,
nParameters = nCov + 1) %*% mlePath[55, ])
parameterIndices <- i + 0:(length(breaks) - 2) * (nCov + 1)
plot(1, type="n", xlab="", ylab="", xlim=c(0, 300), ylim = c(-6, 1))
segments(x0 = 0, y0 = originalParam[parameterIndices[1]], x1 = breaks[2])
for(j in 2:(length(breaks) - 1)){
segments(x0 = breaks[j], y0 = originalParam[parameterIndices[j]], x1 = breaks[j + 1])
}
}
}
makePlot(cvSolution, nCov, breaks)
## penalized brier
## find some optimal parameters
censoringFit <- survfit(Surv(timeVar, 1 - d01) ~ 1)
censoringProb <- predictSurvProb(censoringFit, newdata = simData, times =  evalTimes)
## pretty inneficient way of doing this but ok ...
censoringProb2 <- diag(predictSurvProb(censoringFit, newdata = simData,
times =  simData$timeVar))[rank(simData$timeVar)]
censoringProb2[censoringProb2 == 0] <- min(censoringProb2[censoringProb2 != 0])
penalizedPathBrier(timeVar = simData$timeVar,
d01 = simData$d01,
X = as.matrix(simData[, ! names(simData) %in% c("timeVar", "d01")]),
evalTimes = evalTimes,
cProbEvalTimes =  censoringProb,
cProbTimeVar = censoringProb2,
breaks = c(0, 75, Inf),
lambdaSeq = 10^(- seq(2, 4, 0.1)))
oldSol <- init
initStep <- stepSize
IPWWeights <- exY^(1 - d01)
epsilon = 10^(-5)
stepSize = 0.01
bbSteps = T
maxStep = 10^(5)
minStep = 10^(-5)
oldSol <- init
initStep <- stepSize
IPWWeights <- exY^(1 - d01)
IPWWeights <- IPWWeights / pmax(as.numeric(cProbEvalTimes), cProbTimeVar)
init <-
init = c(log(sum(d01) / sum(timeVar)), 0, 5, 0, 0, 0, 0, 0, 0 ,0)
X
oldSol <- init
initStep <- stepSize
IPWWeights <- exY^(1 - d01)
library(RobustAFT)
firstIndexIncInterval <- function(evalTimes, breaks){
## function that returns the indices of the breaks vector
## for which the evalTimes value falls between that element
## and the next element of the breaks vector
tempMatrix <- matrix(rep(breaks, length(evalTimes)), ncol = length(breaks), byrow = T)
rowSums(tempMatrix <= evalTimes)
}
predictPCH <- function(parameters, breaks, X, evalTimes){
## Function to calculate the predicted survival of new observations
## at the times provided.
## ARGS:
##   parameters: a vector containing the intercepts and coefficients,
##               the structure should be as follows: first the first intercept
##               then the coefficients corresponding to the first interval
##   breaks: the breakpoints
##   X: covariate matrix
##   evalTimes: times for which predictions should be returned
## split the parameters into a matrix of coefficients, with columns corresponding
## to coefficients and rows to intervals, and a vector of intercepts
nCoef <- ncol(X)
nIntervals <- length(breaks) - 1
coef <- matrix(parameters[- seq(from = 1, to = length(parameters), by = nCoef + 1)],
ncol = nCoef, byrow = T)
intercept <- parameters[seq(from = 1, to = length(parameters), by = nCoef + 1)]
## case of and exponential model (i.e. breaks = c(0, Inf) or length(breaks) == 2)
if(length(breaks) == 2){
estCumHaz <- do.call(cbind, lapply(1:length(evalTimes),
function(x) (evalTimes[x] - breaks[1]) *
exp(intercept[1] +
as.numeric(X %*% coef[1, ]))))
## return the survival estimates
predicted <- exp(- estCumHaz)
return(predicted)
}
## fill a matrix with the hazard contribution of the intervalls that are fully
## covered at the evaluation times
fullHaz <- matrix(0,
nrow = nrow(X),
ncol = (length(breaks) - 2))
for(j in 1:(length(breaks) - 2)){
fullHaz[, j] <- as.numeric((breaks[j + 1] - breaks[j]) *
exp(intercept[j] + X %*% coef[j, ]))
}
## sum the different chunks into a cumulative hazards
fullHaz <- t(apply(fullHaz, 1, cumsum))
if(length(breaks) == 3){
## if there are only 2 intervals, the result of the apply is a vector,
## to make everything consistent this is turned into the correct matrix
fullHaz <- t(fullHaz)
}
## create some help-vectors to show to which interval the different evaluation times belong
intPlus1 <- firstIndexIncInterval(evalTimes, breaks)
zeroIntervalsCovered <- sum(intPlus1 == 1)
fullyCoveredIntervals <- intPlus1[!(intPlus1 == 1)]
## calculate the cumulative hazard
estCumHaz <- cbind(matrix(0,
nrow = nrow(X),
ncol = zeroIntervalsCovered),
fullHaz[, fullyCoveredIntervals - 1]) +
do.call(cbind, lapply(1:length(evalTimes),
function(x) (evalTimes[x] - breaks[intPlus1[x]]) *
exp(intercept[intPlus1[x]] +
as.numeric(X %*% coef[intPlus1[x], ]))))
## return the survival estimates
predicted <- exp(-estCumHaz)
predicted
}
timeAtRisk <- function(evalTimes, breaks, ncolRep, nrowRep){
## function that creates a matrix with as components the time in the interval.
## the rows correspond with the evalTimes the columns with the intervals
## each row is repeated nrowRep times (usually the number of observations)
## and each column is repeated ncolRepTimes (usually the number of covariates)
diffMatrix <- matrix(rep(diff(breaks), length(evalTimes)), byrow = T, nrow = length(evalTimes))
colIndices <- firstIndexIncInterval(evalTimes, breaks)
## there might be a more efficient (vectorized) way to do this:
diffMatrix[cbind(1:length(evalTimes), colIndices)] <- evalTimes - breaks[colIndices]
for(i in 1:length(evalTimes)){
if(colIndices[i] + 1 < length(breaks)){
diffMatrix[i, (colIndices[i] + 1):ncol(diffMatrix)] <- 0
}
}
diffMatrix <- diffMatrix[rep(1:nrow(diffMatrix), each = nrowRep), ]
diffMatrix[, rep(1:ncol(diffMatrix), each = ncolRep)]
}
extendedY <- function(evalTimes, timeVar){
## function that transforms the time variable into
## a new outcome variable with length(evaltimes) * lenght(timeVar) entries
## such that the entries are as specified in the least squares equations.
rep(timeVar, length(evalTimes)) > rep(evalTimes, each = length(timeVar))
}
paramTransMat <- function(nIntervals, nParameters){
matrixOfOnes <- kronecker(matrix(1, ncol = nIntervals, nrow = nIntervals),
diag(nParameters))
matrixOfOnes[upper.tri(matrixOfOnes)] <- 0
matrixOfOnes
}
getBrierScore <- function(timeVar, d01, X, cProbEvalTimes, cProbTimeVar, evalTimes,
parameters, breaks, difParam = T){
## A function that returns the Brier score for a PCH model
## the censoringProb should include estimations of the censoring probability with
## rows corresponding to observations and columns to the evalTimes
if(difParam){
parameters <-  paramTransMat(nIntervals = length(breaks) - 1,
nParameters = ncol(X) + 1) %*% parameters
}
## calculate an "extended" Y to calculate quadratic errors from
exY <- extendedY(evalTimes, timeVar)
## get the survival estimates given by a pch model at the evalTimes
predictedSurvival <- predictPCH(parameters, breaks, X, evalTimes)
## calculate the IPW weights
IPWWeights <- (rep(timeVar, length(evalTimes)) <= rep(evalTimes, each = length(timeVar)))^
(1 - rep(d01, length(evalTimes)))
IPWWeights <- IPWWeights / pmax(as.numeric(cProbEvalTimes), cProbTimeVar)
## us the quadratic representation of hte Brier score to just get a mean of squared errors
mean(IPWWeights * (exY - predictedSurvival)^2)
}
getPenalty <- function(param, nParam){
nInterval <- length(param) / nParam
penalty <- 0
for(i in 1:nParam){
paramIndices <- i + (1:(nInterval - 1)) * nParam
penalty <- penalty + sqrt(sum(param[paramIndices]^2))
}
penalty
}
proximalStep <- function(curSol, nParam, gradient, stepsize, lambda){
## Perform a proximal gradient descent step corresponding to a group lasso of differences penalty
## the curSol is the current solution (in differences representation),
## the gradient is the gradient (in differences representation),
## the stepsize is the stepzise that should be taken during the proximal gradient descent step
## lambda is the penalization parameter
nInterval <- length(curSol) / nParam
newSol <- curSol - stepsize * gradient
if(lambda != 0){
for(i in 1:nParam){
paramIndices <- i + (1:(nInterval - 1)) * nParam
stepNorm <- sqrt(sum(newSol[paramIndices]^2))
if(stepNorm <= lambda * stepsize){
newSol[paramIndices] <- 0
} else {
newSol[paramIndices] <- newSol[paramIndices] -
lambda * stepsize * (newSol[paramIndices]) / stepNorm
}
}
}
newSol
}
brierGradient <- function(IPWWeights, timeAtRiskMat, exY, evalTimes, transformMat, largeX, X, parameters, breaks){
oPar <- transformMat %*% parameters
predictedSurvival <- as.numeric(predictPCH(oPar, breaks, X, evalTimes))
gradient <- NULL
X2 <- cbind(1, X)
for(i in 1:(length(breaks) - 1)){
gradient <- c(gradient, t(IPWWeights * (exY - predictedSurvival) * predictedSurvival * timeAtRiskMat[, i] *
as.numeric(exp(X2 %*% oPar[1:(ncol(X2)) + (i - 1) * ncol(X2)]))) %*% largeX)
}
t(transformMat) %*% gradient / (length(IPWWeigths))
}
penalizedBrier <- function(timeVar, d01, X, evalTimes,
cProbEvalTimes, cProbTimeVar,
breaks, init,
lambda,
epsilon = 10^(-5),
stepSize = 0.01,
bbSteps = T,
maxStep = 10^(5),
minStep = 10^(-5)){
# init is the initial solution (in the differences parameterization)
# perform the first step and set-up some vectors
oldSol <- init
initStep <- stepSize
## calculate some data that's used in the gradient
exY <- extendedY(evalTimes = evalTimes,
timeVar = timeVar)
IPWWeights <- exY^(1 - d01)
IPWWeights <- IPWWeights / pmax(as.numeric(cProbEvalTimes), cProbTimeVar)
timeAtRiskMat <- timeAtRisk(evalTimes, breaks, 1, length(timeVar))
transformMat <- paramTransMat(nIntervals = length(breaks) - 1,
nParameters = ncol(X) + 1)
largeX <- X2[rep(1:length(timeVar), length(evalTimes)), ]
gradientOld <- brierGradient(IPWWeights = IPWWeights,
timeAtRiskMat = timeAtRiskMat,
exY = exY,
evalTimes = evalTimes,
transformMat = transformMat,
largeX = largeX,
X = X,
evalTimes = evalTimes,
parameters = oldSol,
breaks =  breaks)
newSol <- proximalStep(oldSol,
ncol(X) + 1,
gradientOld,
stepSize,
lambda)
gradientCur <- gradientOld
i <- 1
solDif <- epsilon + 1
while((max(abs(gradientCur)) > epsilon) & sum(abs(solDif)) > epsilon){
#  Barzilai-Borwein steps
gradientCur <- brierGradient(IPWWeights = IPWWeights,
timeAtRiskMat = timeAtRiskMat,
exY = exY,
evalTimes = evalTimes,
transformMat = transformMat,
largeX = largeX,
X = X,
evalTimes = evalTimes,
parameters = newSol,
breaks =  breaks)
solDif <- newSol - oldSol
if(bbSteps){
gradientDif <- gradientCur - gradientOld
gradientOld <- gradientCur
stepSize <- sum(gradientDif * solDif) / sum(gradientDif^2)
if(is.na(stepSize) | stepSize < 0){
stepSize <- initStep
} else if(stepSize < minStep) {
stepSize <- minStep
} else if(stepSize > maxStep){
stepSize <- maxStep
}
}
oldSol <- newSol
newSol <- proximalStep(newSol,
ncol(X) + 1,
gradientCur,
stepSize,
lambda)
solDif <- newSol - oldSol
i <- i + 1
}
newSol
}
## way of starting a good starting value for the optimization algorithm
trimmedStarts <- function(timeVar, d01, X, cProbEvalTimes,
cProbTimeVar, evalTimes, ntry = 100,
seed = NULL, alpha = 0.8){
if(!is.null(seed)){
set.seed(seed)
}
tempFrame <- data.frame(timeVar, d01, X)
bestSol <- - survreg(formula = Surv(timeVar, d01) ~., tempFrame, dist = "exponential")$coef
bestBrier <- getBrierScore(timeVar, d01, X, cProbEvalTimes,
cProbTimeVar, bestSol, breaks = c(0, Inf),
difParam = F, evalTimes = evalTimes)
for(i in 1:ntry){
curSample <- sample(length(timeVar), size = length(timeVar) * alpha)
curSol <- - survreg(formula = Surv(timeVar, d01) ~., tempFrame[curSample, ], dist = "exponential")$coef
curBrier <- getBrierScore(timeVar, d01, X, cProbEvalTimes,
cProbTimeVar, curSol, breaks = c(0, Inf),
difParam = F, evalTimes = evalTimes)
if(curBrier < bestBrier){
bestBrier <- curBrier
bestSol <- curSol
}
}
bestSol
}
penalizedPathBrier <- function(timeVar, d01, X, evalTimes,
cProbEvalTimes, cProbTimeVar,
breaks, lambdaSeq, ...){
solutions <- matrix(0, nrow = length(lambdaSeq), ncol = (ncol(X) + 1) * (length(breaks) - 1))
# initSol <- trimmedStarts(timeVar = timeVar, d01 = d01, X = X, cProbEvalTimes = cProbEvalTimes,
#                       cProbTimeVar = cProbTimeVar, evalTimes = evalTimes, ntry = 100)
TMLObj <- TML.censored(log(timeVar) ~ .,
simData$d01,
data = simData[, !names(simData) %in% "d01"],
errors = "logWeibull")
initSol <- - TMLObj$th1 / TMLObj$v1
solutions[1, ] <- penalizedBrier(timeVar = timeVar, d01 = d01, X = X, cProbEvalTimes = cProbEvalTimes,
cProbTimeVar = cProbTimeVar, evalTimes = evalTimes, breaks = breaks,
init = c(initSol, rep(0, (ncol(X) + 1)* (length(breaks) - 2))),
lambda = lambdaSeq[1])
for(i in 2:length(lambdaSeq)){
solutions[i, ] <- penalizedBrier(timeVar = timeVar, d01 = d01, X = X, cProbEvalTimes = cProbEvalTimes,
cProbTimeVar = cProbTimeVar, evalTimes = evalTimes, breaks = breaks,
init = solutions[i - 1, ], lambda = lambdaSeq[i])
}
solutions
}
mleGradient <- function(O, R, X2, breaks, parameters){
nInterval <- length(breaks) - 1
## calculate the parameters in the standard parameterization
nIntervals = length(breaks) - 1
nParameters <- length(parameters) / nIntervals
transformMat <- paramTransMat(nIntervals,
nParameters)
originalParameters <- transformMat %*% parameters
gradient <- NULL
for(j in 1:(length(breaks) - 1)){
gradient <- c(gradient,
t(O[, j]) %*% X2 -
t(R[, j]) %*% (as.numeric(exp(X2 %*% originalParameters[1:ncol(X2) + (j - 1) * ncol(X2)]))
* X2))
}
- 1 * t(transformMat) %*% gradient / (length(timeVar))
}
penalizedMLE <- function(timeVar, d01, X,
breaks, init,
lambda, epsilon = 10^(-8),
stepSize = 0.01,
bbSteps = T){
# init is the initial solution (in the differences parameterization)
# perform the first step and set-up some vectors
oldSol <- init
# create some objects needed in the gradient
R <- timeAtRisk(timeVar, breaks, 1, 1)
lastIndex <- firstIndexIncInterval(timeVar, breaks)
O <- matrix(0, ncol = ncol(R), nrow = nrow(R))
O[cbind(1:length(timeVar), lastIndex)] <- d01
X2 <- cbind(1, X)
gradientOld <- mleGradient(O, R, X2, breaks, oldSol)
newSol <- proximalStep(oldSol,
ncol(X) + 1,
gradientOld,
stepSize,
lambda)
i <- 1
solDif <- epsilon + 1
gradientCur <- epsilon + 1
while((max(gradientCur^2) > epsilon) & sum(solDif^2) > epsilon){
#  Barzilai-Borwein steps
gradientCur <- mleGradient(O, R, X2, breaks, newSol)
solDif <- newSol - oldSol
if(bbSteps){
gradientDif <- gradientCur - gradientOld
gradientOld <- gradientCur
stepSize <- sum(gradientDif * solDif) / sum(gradientDif^2)
}
oldSol <- newSol
newSol <- proximalStep(newSol,
ncol(X) + 1,
gradientCur,
stepSize,
lambda)
solDif <- newSol - oldSol
i <- i + 1
}
newSol
}
penalizedPathMLE <- function(timeVar, d01, X, breaks,
lambdaSeq, ...){
solutions <- matrix(0, nrow = length(lambdaSeq), ncol = (ncol(X) + 1) * (length(breaks) - 1))
tempFrame <- data.frame(timeVar, d01, X)
initSol <- - coef(survreg(Surv(timeVar, d01) ~. , data = tempFrame, dist = "exponential"))
solutions[1, ] <- penalizedMLE(timeVar = timeVar, d01 = d01, X = X, breaks = breaks,
init = c(initSol, rep(0, (ncol(X) + 1)* (length(breaks) - 2))),
lambda = lambdaSeq[1])
for(i in 2:length(lambdaSeq)){
solutions[i, ] <- penalizedMLE(timeVar = timeVar, d01 = d01, X = X, breaks = breaks,
init = solutions[i - 1, ], lambda = lambdaSeq[i])
}
solutions
}
lambdaMaxMLE <- function(timeVar, d01, X, breaks){
nParam <- (ncol(X) + 1)
# create some objects needed in the gradient
R <- timeAtRisk(timeVar, breaks, 1, 1)
lastIndex <- firstIndexIncInterval(timeVar, breaks)
O <- matrix(0, ncol = ncol(R), nrow = nrow(R))
O[cbind(1:length(timeVar), lastIndex)] <- d01
X2 <- cbind(1, X)
tempFrame <- data.frame(timeVar, d01, X)
initSol <- - coef(survreg(Surv(timeVar, d01) ~. , data = tempFrame, dist = "exponential"))
mleGrad <- mleGradient(O, R, X2, breaks = breaks,
parameters = c(initSol, rep(0, (nParam)* (length(breaks) - 2))))
nIntervals <- length(breaks) - 1
lambdaMax <- 0
for(i in 1:nParam){
paramIndices <- i + (1:(nIntervals - 1)) * nParam
gradientNorm <- sqrt(sum(mleGrad[paramIndices]^2))
if(gradientNorm > lambdaMax){
lambdaMax <- gradientNorm
}
}
lambdaMax
}
cvMLE <- function(timeVar, d01, X, breaks,
nLambda = 20, logLamdaRatio = 5, nFolds = 10, ...){
logMaxLambda <- - log(lambdaMaxMLE(timeVar = timeVar, d01 = d01, breaks = breaks, X = X))
lambdaSeq <- exp(- seq(logMaxLambda * (1 - logMaxLambda/nLambda) , logMaxLambda*logLamdaRatio, length.out = nLambda))
# sample CV indices
randSample <- sample(nrow(X))
CVIndicesList <- split(randSample, ceiling(seq_along(randSample)/(length(randSample)/nFolds)))
brierScores <- rep(0, nLambda)
for(i in 1:nFolds){
trTimeVar <- timeVar[- CVIndicesList[[i]]]
testTimeVar <- timeVar[CVIndicesList[[i]]]
trd01 <- d01[- CVIndicesList[[i]]]
testd01 <- d01[CVIndicesList[[i]]]
trX <- X[- CVIndicesList[[i]], ]
testX <- X[CVIndicesList[[i]], ]
foldPath <- penalizedPathMLE(timeVar = trTimeVar, d01 = trd01,
X = trX, breaks = breaks,
lambdaSeq = lambdaSeq)
for(j in 1:nLambda){
brierScores[j] <- brierScores[j] + getBrierScore(testTimeVar,
d01 = testd01,
parameters = foldPath[j, ],
evalTimes = evalTimes,
X = testX,
cProbEvalTimes = cProbEvalTimes[CVIndicesList[[i]]],
cProbTimeVar = cProbTimeVar[CVIndicesList[[i]]],
breaks = breaks,
difParam = T)
}
}
solutionPath <- penalizedPathMLE(timeVar = timeVar, d01 = d01,
X = X, breaks = breaks,
lambdaSeq = lambdaSeq)
solutionPath[which.min(brierScores), ]
}
penalizedPathBrier(timeVar = simData$timeVar,
d01 = simData$d01,
X = as.matrix(simData[, ! names(simData) %in% c("timeVar", "d01")]),
evalTimes = evalTimes,
cProbEvalTimes =  censoringProb,
cProbTimeVar = censoringProb2,
breaks = c(0, 75, Inf),
lambdaSeq = 10^(- seq(2, 4, 0.1)))
